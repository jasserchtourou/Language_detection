{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gw6yTX5fRcW4"
      },
      "outputs": [],
      "source": [
        "from langdetect import detect, DetectorFactory\n",
        "import langid\n",
        "from transformers import pipeline\n",
        "import fasttext\n",
        "\n",
        "\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "language_identifier = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
        "\n",
        "fasttext_model = fasttext.load_model('/content/lid.176.bin')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_language_langdetect(text):\n",
        "    try:\n",
        "        language = detect(text)\n",
        "        return language\n",
        "    except:\n",
        "        return \"unknown\"\n",
        "\n",
        "def detect_language_langid(text):\n",
        "    lang, _ = langid.classify(text)\n",
        "    return lang\n",
        "\n",
        "def detect_language_huggingface(text):\n",
        "    truncated_text = text[:512]\n",
        "\n",
        "    result = language_identifier(truncated_text)\n",
        "    return result[0]['label']\n",
        "\n",
        "\n",
        "\n",
        "def detect_language_fasttext(text):\n",
        "    predictions = fasttext_model.predict(text)\n",
        "    return predictions[0][0].replace('__label__', '')\n",
        "\n",
        "def jasser_language_identification(text):\n",
        "    lang_detect_result = detect_language_langdetect(text)\n",
        "    lang_id_result = detect_language_langid(text)\n",
        "    hf_result = detect_language_huggingface(text)\n",
        "    ft_result = detect_language_fasttext(text)\n",
        "\n",
        "    languages = {}\n",
        "\n",
        "    for lang in [lang_detect_result, lang_id_result, hf_result, ft_result]:\n",
        "        if lang in languages:\n",
        "            languages[lang] += 1\n",
        "        else:\n",
        "            languages[lang] = 1\n",
        "\n",
        "    most_common_language = max(languages, key=languages.get)\n",
        "    return most_common_language\n"
      ],
      "metadata": {
        "id": "vIEi2hpkRpGb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing:**"
      ],
      "metadata": {
        "id": "f6tAy2C5cYcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = {\n",
        "    \"Anglais\": \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Français\": \"Le renard brun rapide saute par-dessus le chien paresseux.\",\n",
        "    \"Espagnol\": \"El zorro marrón rápido salta sobre el perro perezoso.\",\n",
        "    \"Allemand\": \"Der schnelle braune Fuchs springt über den faulen Hund.\",\n",
        "    \"Arabe\": \"الثعلب البني السريع يقفز فوق الكلب الكسول.\",\n",
        "    \"Chinois\": \"快速的棕色狐狸跳过懒狗。\",\n",
        "    \"Japonais\": \"速い茶色のキツネが怠惰な犬を飛び越えます。\",\n",
        "    \"Russe\": \"Быстрая коричневая лиса прыгает через ленивую собаку.\",\n",
        "    \"Italien\": \"La volpe marrone veloce salta sopra il cane pigro.\",\n",
        "    \"Portugais\": \"A rápida raposa marrom pula sobre o cão preguiçoso.\"\n",
        "}\n",
        "\n",
        "for language, text in texts.items():\n",
        "    detected_language = jasser_language_identification(text)\n",
        "    print(f\"Langue attendue : {language} - Langue détectée : {detected_language}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O45X3JcyRpTo",
        "outputId": "3b9d7c32-947e-4617-ff45-e3a573deeca5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langue attendue : Anglais - Langue détectée : en\n",
            "Langue attendue : Français - Langue détectée : fr\n",
            "Langue attendue : Espagnol - Langue détectée : es\n",
            "Langue attendue : Allemand - Langue détectée : de\n",
            "Langue attendue : Arabe - Langue détectée : ar\n",
            "Langue attendue : Chinois - Langue détectée : zh\n",
            "Langue attendue : Japonais - Langue détectée : ja\n",
            "Langue attendue : Russe - Langue détectée : ru\n",
            "Langue attendue : Italien - Langue détectée : it\n",
            "Langue attendue : Portugais - Langue détectée : pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the model:**"
      ],
      "metadata": {
        "id": "VscvmQMtcfJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language_map = {\n",
        "    \"en\": \"Anglais\",\n",
        "    \"fr\": \"Français\",\n",
        "    \"es\": \"Espagnol\",\n",
        "    \"de\": \"Allemand\",\n",
        "    \"ar\": \"Arabe\",\n",
        "    \"zh\": \"Chinois\",\n",
        "    \"ja\": \"Japonais\",\n",
        "    \"ru\": \"Russe\",\n",
        "    \"it\": \"Italien\",\n",
        "    \"pt\": \"Portugais\"\n",
        "}\n",
        "\n",
        "# Fonction pour évaluer la précision de la détection de langue\n",
        "def evaluate_language_detection(texts):\n",
        "    correct_count = 0\n",
        "    total_count = len(texts)\n",
        "\n",
        "    for expected_language, text in texts.items():\n",
        "        detected_language_code = jasser_language_identification(text)\n",
        "        detected_language = language_map.get(detected_language_code, \"Unknown\")\n",
        "\n",
        "        print(f\"Langue attendue : {expected_language} - Langue détectée : {detected_language}\")\n",
        "\n",
        "        if detected_language == expected_language:\n",
        "            correct_count += 1\n",
        "\n",
        "    accuracy = correct_count / total_count\n",
        "    print(f\"Précision : {accuracy:.2%}\")\n",
        "\n",
        "# Évaluer la précision de la détection de langue\n",
        "evaluate_language_detection(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1OHjHUNb2nk",
        "outputId": "3269dfb9-de75-432e-bad9-3b15ba489136"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langue attendue : Anglais - Langue détectée : Anglais\n",
            "Langue attendue : Français - Langue détectée : Français\n",
            "Langue attendue : Espagnol - Langue détectée : Espagnol\n",
            "Langue attendue : Allemand - Langue détectée : Allemand\n",
            "Langue attendue : Arabe - Langue détectée : Arabe\n",
            "Langue attendue : Chinois - Langue détectée : Chinois\n",
            "Langue attendue : Japonais - Langue détectée : Japonais\n",
            "Langue attendue : Russe - Langue détectée : Russe\n",
            "Langue attendue : Italien - Langue détectée : Italien\n",
            "Langue attendue : Portugais - Langue détectée : Portugais\n",
            "Précision : 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation of the model with long texts:**"
      ],
      "metadata": {
        "id": "e5nP4flrcEmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs = {\n",
        "    \"Anglais\": \"The quick brown fox jumps over the lazy dog. It was a sunny day in the park. Birds were chirping and people were enjoying their picnics. The fox, satisfied with its jump, rested under a shady tree.\",\n",
        "    \"Français\": \"Le renard brun rapide saute par-dessus le chien paresseux. C'était une journée ensoleillée au parc.Les oiseaux chantaient et les gens profitaient de leurs pique-niques. Le renard, satisfait de son saut, se reposa sous un arbre ombragé.\",\n",
        "    \"Espagnol\": \"El zorro marrón rápido salta sobre el perro perezoso. Era un día soleado en el parque. Los pájaros cantaban y la gente disfrutaba de sus picnics. El zorro, satisfecho con su salto, descansó bajo un árbol sombrío.\",\n",
        "    \"Allemand\": \"Der schnelle braune Fuchs springt über den faulen Hund. Es war ein sonniger Tag im Park. Die Vögel zwitscherten und die Leute genossen ihre Picknicks. Der Fuchs, zufrieden mit seinem Sprung, ruhte unter einem schattigen Baum.\",\n",
        "    \"Arabe\": \"الثعلب البني السريع يقفز فوق الكلب الكسول. كان يومًا مشمسًا في الحديقة. كانت الطيور تغرد وكان الناس يستمتعون بنزهاتهم. الثعلب، راضيًا عن قفزته، استراح تحت شجرة ظليلة\",\n",
        "\n",
        "    \"Chinois\": \"快速的棕色狐狸跳过懒狗。 这是公园里的一个阳光明媚的日子。 鸟儿在唱歌，人们在享受野餐。 狐狸满意地跳了跳，在一棵荫凉的树下休息。\",\n",
        "    \"Japonais\": \" 速い茶色のキツネが怠惰な犬を飛び越えます。 公園は晴れた日でした。 鳥がさえずり、人々がピクニックを楽しんでいました。 キツネはその飛び越えに満足し、日陰の木の下で休憩しました。\",\n",
        "    \"Russe\": \" Быстрая коричневая лиса прыгает через ленивую собаку. Это был солнечный день в парке. Птицы щебечут,  а люди наслаждаются пикниками. Лиса, удовлетворенная своим прыжком, отдохнула под тенью дерева.\",\n",
        "    \"Italien\": \"La volpe marrone veloce salta sopra il cane pigro. Era una giornata soleggiata al parco. Gli uccelli cinguettavano e le persone stavano godendo dei loro picnic. La volpe, soddisfatta del suo salto, si riposò sotto un albero ombroso.\",\n",
        "    \"Portugais\": \" A rápida raposa marrom pula sobre o cão preguiçoso. Foi um dia ensolarado no parque. Os pássaros estavam cantando  e as pessoas estavam aproveitando seus piqueniques. A raposa, satisfeita com seu salto, descansou sob uma árvore sombreada.\"\n",
        "}\n",
        "\n",
        "evaluate_language_detection(paragraphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YzWwbTDcSWM",
        "outputId": "de82711e-7e1e-40d0-bff6-abac6f9f1670"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langue attendue : Anglais - Langue détectée : Anglais\n",
            "Langue attendue : Français - Langue détectée : Français\n",
            "Langue attendue : Espagnol - Langue détectée : Espagnol\n",
            "Langue attendue : Allemand - Langue détectée : Allemand\n",
            "Langue attendue : Arabe - Langue détectée : Arabe\n",
            "Langue attendue : Chinois - Langue détectée : Chinois\n",
            "Langue attendue : Japonais - Langue détectée : Japonais\n",
            "Langue attendue : Russe - Langue détectée : Russe\n",
            "Langue attendue : Italien - Langue détectée : Italien\n",
            "Langue attendue : Portugais - Langue détectée : Portugais\n",
            "Précision : 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation of the model with complex sentencesl:**"
      ],
      "metadata": {
        "id": "Z13xb5EPdpbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = {\n",
        "    \"Anglais\": \"Artificial intelligence (AI) is transforming industries worldwide. From healthcare to finance, AI is driving innovation and improving efficiency. However, ethical concerns around AI algorithms continue to grow, highlighting the need for responsible AI development.\",\n",
        "    \"Français\": \"L'intelligence artificielle (IA) transforme les industries du monde entier. De la santé à la finance, l'IA stimule l'innovation et améliore l'efficacité. Cependant, les préoccupations éthiques concernant les algorithmes d'IA ne cessent de croître, soulignant la nécessité d'un développement responsable de l'IA.\",\n",
        "    \"Espagnol\": \"La inteligencia artificial (IA) está transformando industrias en todo el mundo. Desde la atención médica hasta las finanzas, la IA impulsa la innovación y mejora la eficiencia. Sin embargo, las preocupaciones éticas en torno a los algoritmos de IA continúan creciendo, destacando la necesidad de un desarrollo ético de la IA.\",\n",
        "    \"Allemand\": \"  Künstliche Intelligenz (KI) transformiert weltweit Branchen. Von der Gesundheitsversorgung bis zur Finanzwirtschaft treibt KI Innovationen voran und verbessert die Effizienz.   Dennoch nehmen die ethischen Bedenken hinsichtlich KI-Algorithmen zu,   was die Notwendigkeit einer verantwortungsvollen Entwicklung von KI betont. \",\n",
        "    \"Chinois\": \"人工智能（AI）正在全球范围内改变各行各业。 从医疗保健到金融，AI推动创新并提高效率。 然而，围绕AI算法的伦理关注不断增长，突显了开发责任感AI的必要性。\",\n",
        "    \"Japonais\": \"人工知能（AI）は世界中の産業を変革しています。 医療から金融まで、AIは革新を推進し、効率を向上させています。 しかし、AIアルゴリズムに関する倫理的な懸念は高まり続けており、 責任あるAIの開発の必要性を示しています。\",\n",
        "    \"Russe\": \"Искусственный интеллект (ИИ) трансформирует отрасли по всему миру.  От здравоохранения до финансов, ИИ стимулирует инновации и повышает эффективность. Однако этические вопросы, связанные с алгоритмами ИИ, продолжают расти,  подчеркивая необходимость ответственного развития ИИ. \",\n",
        "    \"Italien\": \" L'intelligenza artificiale (AI) sta trasformando industrie in tutto il mondo.  Dalla sanità alle finanze, l'AI sta guidando l'innovazione e migliorando l'efficienza.  Tuttavia, le preoccupazioni etiche riguardanti gli algoritmi di AI continuano a crescere,  evidenziando la necessità di uno sviluppo responsabile dell'AI.\",\n",
        "    \"Portugais\": \"  A inteligência artificial (AI) está transformando indústrias em todo o mundo.   Da saúde às finanças, a AI está impulsionando a inovação e melhorando a eficiência.   No entanto, as preocupações éticas em torno dos algoritmos de AI continuam a crescer,   destacando a necessidade de um desenvolvimento responsável de AI.\"\n",
        "}\n",
        "\n",
        "evaluate_language_detection(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbYPXVBhd3yL",
        "outputId": "ad7a204a-a000-4ab4-85f7-2a760bb39be3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langue attendue : Anglais - Langue détectée : Anglais\n",
            "Langue attendue : Français - Langue détectée : Français\n",
            "Langue attendue : Espagnol - Langue détectée : Espagnol\n",
            "Langue attendue : Allemand - Langue détectée : Allemand\n",
            "Langue attendue : Chinois - Langue détectée : Chinois\n",
            "Langue attendue : Japonais - Langue détectée : Japonais\n",
            "Langue attendue : Russe - Langue détectée : Russe\n",
            "Langue attendue : Italien - Langue détectée : Italien\n",
            "Langue attendue : Portugais - Langue détectée : Portugais\n",
            "Précision : 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LanguageIdentificationModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LanguageIdentificationModel, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "I006enHmjPyf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 16\n",
        "hidden_size = 128\n",
        "output_size = 3\n",
        "\n",
        "model = LanguageIdentificationModel(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "input_data = torch.randn(1, input_size)\n",
        "\n",
        "optimizer.zero_grad()\n",
        "output = model(input_data)\n",
        "target = torch.tensor([0])\n",
        "loss = criterion(output, target)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'LanguageIdentificationModel_weights.bin')\n",
        "\n",
        "\n",
        "model = LanguageIdentificationModel(input_size, hidden_size, output_size)\n",
        "model.load_state_dict(torch.load('LanguageIdentificationModel_weights.bin'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhpmiXY9j7kZ",
        "outputId": "30ba9e7c-3956-41f4-86de-a2da2aa45395"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageIdentificationModel(\n",
              "  (fc): Linear(in_features=16, out_features=128, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}